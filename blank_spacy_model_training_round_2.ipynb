{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kspicer/Documents/GitHub/bulk_scotus/blank_spacy_model_training_round_2.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kspicer/Documents/GitHub/bulk_scotus/blank_spacy_model_training_round_2.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kspicer/Documents/GitHub/bulk_scotus/blank_spacy_model_training_round_2.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kspicer/Documents/GitHub/bulk_scotus/blank_spacy_model_training_round_2.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kspicer/Documents/GitHub/bulk_scotus/blank_spacy_model_training_round_2.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kspicer/Documents/GitHub/bulk_scotus/blank_spacy_model_training_round_2.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokens\u001b[39;00m \u001b[39mimport\u001b[39;00m DocBin\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example\n",
    "nlp = spacy.blank('en')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat = nlp.add_pipe('textcat')\n",
    "textcat.add_label(\"1700\")\n",
    "textcat.add_label(\"1800\")\n",
    "textcat.add_label(\"1900\")\n",
    "textcat.add_label(\"2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_html</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us dall led anonymous supreme court pennsylvan...</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us dall led lessee proprietaryvralston supreme...</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us dall led gerardvla coste et al court common...</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us dall led pollardvshaaffer supreme court pen...</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>us dall led pringlevblacks executors supreme c...</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_html  label\n",
       "1  us dall led anonymous supreme court pennsylvan...   1700\n",
       "2  us dall led lessee proprietaryvralston supreme...   1700\n",
       "3  us dall led gerardvla coste et al court common...   1700\n",
       "4  us dall led pollardvshaaffer supreme court pen...   1700\n",
       "5  us dall led pringlevblacks executors supreme c...   1700"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('training_json_file.json')\n",
    "df.head()\n",
    "df['cleaned_html'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['cleaned_html'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df['cleaned_html'].values\n",
    "train_labels = [{\"cats\": {\"1700\": label == 1700,\n",
    "                        \"1800\": label==1800,\n",
    "                        \"1900\": label==1900,\n",
    "                        \"2000\": label==2000}} for label in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_texts, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data[0], train_data[1], test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, optimizer, batch_size=8):\n",
    "    losses = {}\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n",
    "    for batch in minibatch(train_data, size=batch_size):\n",
    "        # Split batch into text and labels\n",
    "        for text, labels in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            # TODO: Update model with texts and labels\n",
    "            nlp.update([example], sgd=optimizer, losses = losses)\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.216501016496\n"
     ]
    }
   ],
   "source": [
    "spacy.util.fix_random_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "losses = train(nlp, train_data, optimizer)\n",
    "print(losses['textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk('saved_spacy_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./texts_for_testing/test_text.json', encoding=\"utf-8\") as f:\n",
    "    test_text = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_of_text = test_text['plain_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_doc = nlp(opinion_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1700': 2.4846047381288372e-05,\n",
       " '1800': 6.585433993677725e-07,\n",
       " '1900': 4.132466528972145e-06,\n",
       " '2000': 0.9999703168869019}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1700': 3.817029937636107e-05,\n",
       " '1800': 5.630177923876545e-08,\n",
       " '1900': 2.2707074549543904e-06,\n",
       " '2000': 0.9999594688415527}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./texts_for_testing/test_text_1.json', encoding='utf-8') as f:\n",
    "    test_text_1 = json.load(f)\n",
    "\n",
    "opinion_of_text_01 = test_text_1['plain_text']\n",
    "spacy_doc_01 = nlp(opinion_of_text_01)\n",
    "spacy_doc_01.cats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7b3036a75e82195f25039e0a24313af0afb91902907fcbdd7fd0983e19573b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
